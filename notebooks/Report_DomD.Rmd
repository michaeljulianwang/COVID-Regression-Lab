---
title: |
  | \vspace{5cm} Lab 2: Impact of Stay at Home Orders on Individual Mobility
author: 'w203: Statistics for Data Science'
date: "Elaine Chang, Dom Dillingham, Jesse Miller, Michael Wang"
output:
  pdf_document: default
---

\newpage 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Your introduction should present a research question and explain the concept that you're attempting to measure and how it will be operationalized. This section should pave the way for the body of the report, preparing the reader to understand why the models are constructed the way that they are. It is not enough to simply say "We are looking for policies that help against COVID."  Your introduction must do work for you, focusing the reader on a specific measurement goal, making them care about it, and propelling the narrative forward. This is also good time to put your work into context, discuss cross-cutting issues, and assess the overall appropriateness of the data.
```

## 2. Model Building

### EDA

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# You will next build a set of models to investigate your research question, documenting your decisions. Here are some things to keep in mind during your model building process:
# 
# 1. *What do you want to measure*? Make sure you identify one key variable (possibly more in rare cases) that will allow you to derive conclusions relevant to your research question, and include this variables in all model specifications.
# 2. Is your modeling goal one of description or explanation? 
# 3. What [covariates](https://en.wikipedia.org/wiki/Dependent_and_independent_variables#Statistics_synonyms) help you achieve your modeling goals? What covariates are problematic, either due to *collinearity*, or because they will absorb some of a causal effect you want to measure?
# 4. What *transformations*, if any, should you apply to each variable? These transformations might reveal linearities in the data, make your results relevant, or help you meet model assumptions.
# 5. Are your choices supported by exploratory data analysis (*EDA*)? You will likely start with some general EDA to *detect anomalies* (missing values, top-coded variables, etc.). From then on, your EDA should be interspersed with your model building. Use visual tools to *guide* your decisions. You can also leverage statistical *tests* to help assess whether variables, or groups of variables, are improving model fit.
# 
# At the same time, it is important to remember that you are not trying to create one perfect model. You will create several specifications, giving the reader a sense of how robust (or sensitive) your results are to modeling choices, and to show that you're not just cherry-picking the specification that leads to the largest effects.
# 
# At a minimum, you should include the following three specifications:
# 
# 1. **Limited Model**: A model that includes *only the key variable* you want to measure and nothing (or almost nothing) else. This variables might be transformed, as determined by your EDA, but the model should include the absolute minimum number of covariates (perhaps one, or at most two-three, covariates if they are so crucial that it would be unreasonable to omit them). 
# 1. **Model Two**: A model that includes *key explanatory variables and covariates that you believe advance your modeling* goals without introducing too much multicollinearity or causing other issues. This model should strike a balance between accuracy and parsimony and reflect your best understanding of the relationships among key variables.
# 1. **Model Three**: A model that includes the *previous covariates, and many other covariates*, erring on the side of inclusion. A key purpose of this model is to evaluate how parameters of interest change (if at all) when additional, potentially colinear variables are included in the model specification.
# 
# Although the models have different emphases, each one must still be a reasonable choice given your modeling goals.  The idea is to choose models that encircle the space of reasonable modeling choices, and to give an overall understanding of how these choices impact results.
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
## Load packages 
library(dplyr)
library(magrittr)
library(lubridate)
library(ggplot2)
library(openxlsx)
library(lmtest)
library(sandwich)
library(stargazer)

## Import datasets
mobility <- read.csv('../data/raw/2020_US_Region_Mobility_Report.csv',
                     stringsAsFactors = F)
stateInfo <- read.xlsx('../data/raw/COVID-19 US state policy database 3_17_2021.xlsx',
                      sheet = 1, detectDates = T) %>%
   ## Filter out the filler rows
  filter(!(STATE %in% c('State', 'category', 'type', 'unit'))) 

ACS <- read.csv('../data/raw/ACSDP1Y2019.DP05-2021-04-04T224220.csv', stringsAsFactors = F)

govParty <- read.csv('../data/raw/Govenor Party.csv', stringsAsFactors = F)

## Bring in COVID data - this is CDC data, not NYT because it's already incremental and easier to work with
COVIDData <- read.csv('../data/raw/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv', stringsAsFactors = F) 

## Subset mobility data down to only state rows and convert the date to a date
stateLevel <- mobility %>% filter(sub_region_1 != '', 
                                  sub_region_2 == '') %>%
                           mutate(Date = ymd(date))

## Subset to just the aggregate US level values for graphs
usLevel <- mobility %>% filter(sub_region_1 == '', 
                               sub_region_2 == '') %>% 
                          mutate(Date = ymd(date))

## ACS data prep

### Get usable variable names
ACS %<>% select(c(Label, contains('Estimate')))
names(ACS) <- gsub('..Estimate', '', names(ACS))
names(ACS) <- gsub('\\.', ' ', names(ACS))

### Transpose the dataframe
ACS <- as.data.frame(t(as.matrix(ACS)))
ACS %<>% tibble::rownames_to_column('State')
ACS[1,1] <- 'State'

names(ACS) <- make.names(as.matrix(ACS[1, ]))

#### Remove the header row
ACS <- ACS[-1, ] 

#### Select down to the columns we want - can't do this by names because of duplicates
ACS <- ACS[, c(1, 3, 6, 10, 11, 20, 30)]

#### Clean up the two vars we want - need to play around because matrix converts to factors
ACS %<>% mutate(Population = as.numeric(gsub(',', '', as.character(X....Total.population))), 
                MedianAge = as.numeric(as.character(X........Median.age..years.)), 
                SexRatio = as.numeric(as.character(X........Sex.ratio..males.per.100.females.)),
                SexRatioGt65 = as.numeric(as.character(X............Sex.ratio..males.per.100.females.)),
                YoungPopPcnt = (as.numeric(gsub(',', '', as.character(X........15.to.19.years))) + as.numeric(gsub(',', '', as.character(X........20.to.24.years)))) / Population
                  ) %>%
  select(-X....Total.population, -X........Median.age..years., -X........Sex.ratio..males.per.100.females.,
         -X............Sex.ratio..males.per.100.females., -X........15.to.19.years, -X........20.to.24.years)

startDate <- '2020-03-15'
endDate <- '2020-06-15'

##  Create the modeling dataset
modDat <- stateLevel %>%
  filter(Date >= startDate,
         Date <= endDate) %>%
  group_by(sub_region_1) %>%
  summarise(y_var = median(retail_and_recreation_percent_change_from_baseline)) %>%
  left_join(stateInfo, by = c('sub_region_1' = 'STATE')) %>%
  mutate(stay = case_when(STAYHOME > 0 ~ '1',
                          TRUE ~ '0'),
         ## This needs to be reviewed in case I messed up the logic
         length = case_when(STAYHOME > 0 & ymd(STAYHOME) > startDate & ymd(END_STHM) < endDate ~ ymd(END_STHM) - ymd(STAYHOME),
                            STAYHOME > 0 & ymd(STAYHOME) > startDate & ymd(END_STHM) > endDate ~ ymd(endDate) - ymd(STAYHOME),
                            STAYHOME > 0 & ymd(STAYHOME) < startDate & ymd(END_STHM) < endDate ~ ymd(END_STHM) - ymd(startDate),
                            STAYHOME > 0 & ymd(STAYHOME) < startDate & ymd(END_STHM) > endDate ~ ymd(endDate) - ymd(startDate),
                            TRUE ~ 0)) %>% 
  left_join(ACS, by = c('sub_region_1' = 'State')) %>%
  left_join(govParty, by = c('sub_region_1' = 'State')) %>%
  left_join(
    COVIDData %>%
      filter(!is.na(submission_date)) %>%
      filter(mdy(submission_date) >= startDate,
             mdy(submission_date) <= endDate) %>%
      group_by(state) %>%
      summarise(new_case = sum(new_case)),
    by = c('POSTCODE' = 'state')
  ) %>%
  mutate(new_case_per_thousand = new_case / Population * 1000)

# write.csv(modDat, 'Dom_processed.csv')

## Prep COVID data to show waves
COVIDout <- COVIDData %>%
  mutate(submission_date = mdy(submission_date)) %>%
  filter(state %in% modDat$POSTCODE,
         !is.na(submission_date)) %>%
  group_by(submission_date) %>%
  summarise(new_cases = sum(new_case))
```

```{r, echo=FALSE, message=FALSE}
ggplot(COVIDout %>% filter(submission_date >= '2020-03-01'), aes(x = submission_date, y = new_cases)) +
  geom_point() + stat_smooth() + ggtitle("Total COVID Case Spread") + 
  labs(y = 'New COVID Cases', x = 'Date')
```

```{r, echo=FALSE, message=FALSE}
ggplot(COVIDout %>% filter(submission_date >= '2020-03-01',
                           submission_date < '2020-07-01'), aes(x = submission_date, y = new_cases)) +
  geom_point() + stat_smooth() + ggtitle("First US COVID Wave") + 
  labs(y = 'New COVID Cases', x = 'Date') + 
  geom_vline(xintercept = as.numeric(ymd('2020-03-15')), linetype='dotted') + 
  geom_vline(xintercept = as.numeric(ymd('2020-06-15')), linetype='dotted') +
  ylim(0,50000)
```

We will begin our analysis by first exploring the Google Mobility dataset. While there are many mobility measures within this dataset, we will focus on the change in mobility for retail and recreation. Unlike the other features that focus on grocery or parks, we beleive that retail and recreation captures the type of activity that stay at home policies intended to reduce. 

```{r, echo=FALSE, message=FALSE}
ggplot(usLevel, aes(x = Date, y = retail_and_recreation_percent_change_from_baseline)) +
  geom_point() + stat_smooth() + ggtitle("U.S. Aggregate Mobility Impact") + 
  labs(y = 'Retail and Recreation Mobility Change', x = 'Date')
```

```{r, echo=FALSE, message=FALSE}
ggplot(modDat, aes(x = y_var)) +
  geom_histogram() + ggtitle("y_var Exploration") 
```

### Model  1

```{r, echo=FALSE, message=FALSE}
ggplot(modDat, aes(x = as.numeric(length))) +
  geom_histogram() + ggtitle("stay Exploration") 
```

```{r, echo=FALSE, message=FALSE}
mod1 <- lm(y_var ~ length
          , data = modDat)
coeftest(mod1, vcov = vcovHC(mod1))
```



### Model 2

```{r, echo=FALSE, message=FALSE}
ggplot(modDat, aes(x = new_case_per_thousand )) +
  geom_histogram() + ggtitle("Cases per Thousand") 
```

```{r, echo=FALSE, message=FALSE}
ggplot(modDat, aes(x = length, fill = Party )) +
  geom_histogram() + ggtitle("Length of Stay at Home by Party") 
```

```{r, echo=FALSE, message=FALSE}
mod2 <- lm(y_var ~ length + Party + new_case_per_thousand
          , data = modDat)
coeftest(mod2, vcov = vcovHC(mod2))
```

```{r, echo=FALSE, message=FALSE}
anova(mod2, mod1, test = "F")
```

### Model 3
```{r, echo=FALSE, message=FALSE}
ggplot(modDat, aes(x = as.numeric(RISKCOV) )) +
  geom_histogram() + ggtitle("Pcnt At-Risk of COVID") 
```

```{r, echo=FALSE, message=FALSE}
ggplot(modDat, aes(x = MedianAge )) +
  geom_histogram() + ggtitle("Unemployment Maximum Amount") 
```

```{r, echo=FALSE, message=FALSE}
mod3 <- lm(y_var ~ length + as.numeric(RISKCOV) +
             MedianAge + Party + new_case_per_thousand
          , data = modDat)
coeftest(mod3, vcov = vcovHC(mod3))
```

```{r, echo=FALSE, message=FALSE}
anova(mod3, mod2, test = "F")
```

### Regression Table and Interpretation
```{r, echo=FALSE, warning=FALSE, message=FALSE}
# 
# You should display all of your model specifications in a regression table, using a package like [`stargazer`](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf) to format your output. It should be easy for the reader to find the coefficients that represent key effects at the top of the regression table, and scan horizontally to see how they change from specification to specification. Make sure that you display the most appropriate standard errors in your table, along with significance stars.
# 
# In your text, comment on both *statistical significance and practical significance*. You may want to include statistical tests besides the standard t-tests for regression coefficients.
```

## 4. Limitations

````{r, echo=FALSE, warning=FALSE, message=FALSE}
# As a team, evaluate all of the CLM assumptions that must hold for your model. However, do not report an exhaustive examination all 5 CLM assumption. Instead, bring forward only those assumptions that you think pose significant problems for your analysis. For each problem that you identify, describe the statistical consequences. If you are able to identify any strategies to mitigate the consequences, explain these strategies. 
# 
# Note that you may need to change your model specifications in response to violations of the CLM. 
```

## 5. Discussion of Omitted Variables

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# If the team has taken up an explanatory (i.e. causal) question to evaluate, then identify what you think are the 5 most important *omitted variables* that bias results you care about. For each variable, you should *reason about the direction of bias* caused by omitting this variable. If you can argue whether the bias is large or small, that is even better. State whether you have any variables available that may proxy (even imperfectly) for the omitted variable. Pay particular attention to whether each omitted variable bias is *towards zero or away from zero*. You will use this information to judge whether the effects you find are likely to be real, or whether they might be entirely an artifact of omitted variable bias.
```

## 6. Conclusion

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Make sure that you end your report with a discussion that distills key insights from your estimates and addresses your research question.
```